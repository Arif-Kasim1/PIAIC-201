{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPpl5O2OA4zoX5DbfBdqXc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arif-Kasim1/PIAIC-201/blob/main/201_PROJECT_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "f4aJ0dwilMX-"
      },
      "outputs": [],
      "source": [
        "%pip install -Uq langchain==0.1.0 langchain-google-genai==0.0.6 pinecone-client==3.0.0 google-generativeai==0.3.2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
        "from langchain_community.vectorstores import Pinecone\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains import RetrievalQA\n",
        "import pinecone\n",
        "import os\n",
        "from typing import List\n",
        "from google.colab import userdata\n",
        "from pinecone import ServerlessSpec # Import the ServerlessSpec\n",
        "import textwrap\n",
        "\n",
        "class SimpleRAG:\n",
        "    def __init__(self, pinecone_api_key: str, google_api_key: str, index_name: str):\n",
        "        \"\"\"\n",
        "        Initialize the RAG system\n",
        "        \"\"\"\n",
        "        # Set up API keys\n",
        "        os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY\")\n",
        "        os.environ[\"PINECONE_API_KEY\"] = userdata.get(\"PINECONE_API_KEY\")\n",
        "\n",
        "        # Initialize Pinecone client (v3)\n",
        "        self.pc = pinecone.Pinecone(api_key=pinecone_api_key)\n",
        "        self.index_name = index_name\n",
        "\n",
        "        # Initialize Gemini components\n",
        "        self.embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "        # Add the convert_system_message_to_human parameter here\n",
        "        self.llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0, convert_system_message_to_human=True)\n",
        "\n",
        "        # Create index if it doesn't exist\n",
        "        if self.index_name not in self.pc.list_indexes().names():\n",
        "            self.pc.create_index(\n",
        "                name=self.index_name,\n",
        "                dimension=768,  # Gemini embedding dimension\n",
        "                metric=\"cosine\",\n",
        "                spec=ServerlessSpec( # Use ServerlessSpec\n",
        "                    cloud=\"aws\",\n",
        "                    region=\"us-east-1\" # Changed region to us-east-1\n",
        "                )\n",
        "            )\n",
        "\n",
        "        # Initialize vector store\n",
        "        self.vector_store = Pinecone.from_existing_index(\n",
        "            index_name=self.index_name,\n",
        "            embedding=self.embeddings\n",
        "        )\n",
        "\n",
        "    def load_documents(self, text: str) -> List[str]:\n",
        "        \"\"\"\n",
        "        Split text into chunks\n",
        "        \"\"\"\n",
        "        splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=1000,\n",
        "            chunk_overlap=100\n",
        "        )\n",
        "        return splitter.split_text(text)\n",
        "\n",
        "    def add_texts(self, texts: List[str]) -> None:\n",
        "        \"\"\"\n",
        "        Add texts to Pinecone\n",
        "        \"\"\"\n",
        "        self.vector_store.add_texts(texts)\n",
        "        print(f\"Added {len(texts)} chunks to Pinecone\")\n",
        "\n",
        "    def query(self, question: str) -> str:\n",
        "        \"\"\"\n",
        "        Query the RAG system\n",
        "        \"\"\"\n",
        "        qa_chain = RetrievalQA.from_chain_type(\n",
        "            llm=self.llm,\n",
        "            retriever=self.vector_store.as_retriever(search_kwargs={\"k\": 3}),\n",
        "            return_source_documents=True\n",
        "        )\n",
        "        response = qa_chain({\"query\": question})\n",
        "        return {\n",
        "            \"answer\": response[\"result\"],\n",
        "            \"sources\": [doc.page_content for doc in response[\"source_documents\"]]\n",
        "        }\n",
        "\n",
        "    def cleanup(self) -> None:\n",
        "        \"\"\"\n",
        "        Delete the Pinecone index\n",
        "        \"\"\"\n",
        "        if self.index_name in self.pc.list_indexes().names():\n",
        "            self.pc.delete_index(self.index_name)\n",
        "            print(f\"Deleted index: {self.index_name}\")\n",
        "\n",
        "# Example usage\n",
        "def main():\n",
        "    # Initialize the RAG system\n",
        "    rag = SimpleRAG(\n",
        "        pinecone_api_key=userdata.get(\"PINECONE_API_KEY\"),\n",
        "        google_api_key=userdata.get(\"GOOGLE_API_KEY\"),\n",
        "        index_name=\"test-index\"\n",
        "    )\n",
        "\n",
        "    # Example text\n",
        "    sample_text = \"\"\"\n",
        "    Artificial Intelligence (AI) is revolutionizing various industries.\n",
        "    Machine Learning, a subset of AI, enables systems to learn from data.\n",
        "    Deep Learning, a type of Machine Learning, uses neural networks with multiple layers.\n",
        "    Natural Language Processing (NLP) allows computers to understand human language.\n",
        "    Computer Vision helps machines interpret and analyze visual information.\n",
        "\n",
        "    Introduction: The Pentium processor series, launched by Intel in 1993,\n",
        "    marked a significant leap in performance over its predecessor, the 486 series.\n",
        "    Architecture: Introduced advanced features like superscalar architecture,\n",
        "    allowing multiple instructions per clock cycle.\n",
        "    Variants: Evolved through multiple generations, including Pentium Pro,\n",
        "    Pentium II, Pentium III, and Pentium 4, offering enhanced speed and functionality.\n",
        "    Technology: Incorporated technologies like MMX, Hyper-Threading, and higher\n",
        "    clock speeds to cater to evolving computing needs.\n",
        "    Legacy: Paved the way for modern processors, blending performance and\n",
        "    efficiency for desktops and laptops.\n",
        "\n",
        "    The future of machine learning (ML) is poised for transformative growth,\n",
        "    driving innovation across industries. Advances in neural networks, quantum\n",
        "    computing, and explainable AI will make ML more powerful and transparent.\n",
        "    It will revolutionize healthcare with precise diagnostics, enhance automation\n",
        "    in manufacturing, and optimize personalized experiences in retail and\n",
        "    entertainment. Ethical AI and robust frameworks will address challenges like\n",
        "    bias and privacy. Seamless integration with IoT, robotics, and edge\n",
        "    computing will bring AI closer to users. As ML democratizes through\n",
        "    accessible tools, its potential to solve global challenges, from climate\n",
        "    change to education, will shape a smarter, sustainable world.\n",
        "\n",
        "    Pakistanis hold a special affection for their traditional dishes, with\n",
        "    biryani, paye, and nihari reigning supreme. Biryani, a fragrant mix of rice,\n",
        "    meat, and spices, is a celebratory dish enjoyed at weddings, festivals, and\n",
        "    casual gatherings. Its rich flavors and endless variations make it a\n",
        "    nationwide favorite. Paye, a slow-cooked delicacy made from trotters,\n",
        "    offers a hearty, flavorful experience often relished during breakfast or\n",
        "    family feasts. Nihari, a spicy stew of tender meat simmered overnight, is\n",
        "    synonymous with comfort food, particularly loved in winters. These dishes\n",
        "    are more than just meals—they represent Pakistan’s rich culinary heritage\n",
        "    and the warmth of sharing food. Served with naan, parathas, or raita, they\n",
        "    bring families and friends together, embodying a deep-rooted tradition of\n",
        "    hospitality. Whether in bustling cities or quiet villages, the love for\n",
        "    biryani, paye, and nihari reflects the soul of Pakistani cuisine.\n",
        "    \"\"\"\n",
        "\n",
        "    # Process and add documents\n",
        "    chunks = rag.load_documents(sample_text)\n",
        "    rag.add_texts(chunks)\n",
        "\n",
        "    # Ask a question\n",
        "    # question = \"What is Machine Learning and how does it relate to AI?\"\n",
        "    # question = \"What is Machine Learning future and how does it relate to AI?\"\n",
        "    # question = \"What is JSP and Servlet?\"\n",
        "    # question = \"Difference between Pentium 2 and Pentium 4?\"\n",
        "    # question = \"Difference between 486 and Pentium?\"\n",
        "\n",
        "    while True:\n",
        "      question = input(\"How can I help you? \")\n",
        "\n",
        "      if question == \"exit\":\n",
        "        break\n",
        "\n",
        "      result = rag.query(question)\n",
        "\n",
        "      # Print results\n",
        "      print(\"\\nQuestion:\", question)\n",
        "      print(\"\\nAnswer:\", textwrap.fill(result[\"answer\"], width=80))\n",
        "      # textwrap.fill(response, width=80)\n",
        "      print(\"\\nSources used:\")\n",
        "      for i, source in enumerate(result[\"sources\"], 1):\n",
        "          print(f\"\\nSource {i}:\", source)\n",
        "\n",
        "      print(\"\\n *********************** \\n\")\n",
        "\n",
        "      # Optional: Clean up\n",
        "      # rag.cleanup()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDFYWIIGmyr2",
        "outputId": "fd30436c-8601-4a1c-bb47-1274c78df344"
      },
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added 5 chunks to Pinecone\n",
            "How can I help you? what is biryani?\n",
            "\n",
            "Question: what is biryani?\n",
            "\n",
            "Answer: The provided context does not contain the answer to the question \"what is\n",
            "biryani?\".\n",
            "\n",
            "Sources used:\n",
            "\n",
            "Source 1: biryani, paye, and nihari reflects the soul of Pakistani cuisine.\n",
            "\n",
            "Source 2: biryani, paye, and nihari reflects the soul of Pakistani cuisine.\n",
            "\n",
            "Source 3: hospitality. Whether in bustling cities or quiet villages, the love for \n",
            "    biryani, paye, and nihari reflects the soul of Pakistani cuisine.\n",
            "\n",
            " *********************** \n",
            "\n",
            "How can I help you? what is ML?\n",
            "\n",
            "Question: what is ML?\n",
            "\n",
            "Answer: Machine Learning (ML)\n",
            "\n",
            "Sources used:\n",
            "\n",
            "Source 1: The future of machine learning (ML) is poised for transformative growth, \n",
            "    driving innovation across industries. Advances in neural networks, quantum \n",
            "    computing, and explainable AI will make ML more powerful and transparent. \n",
            "    It will revolutionize healthcare with precise diagnostics, enhance automation \n",
            "    in manufacturing, and optimize personalized experiences in retail and \n",
            "    entertainment. Ethical AI and robust frameworks will address challenges like\n",
            "    bias and privacy. Seamless integration with IoT, robotics, and edge \n",
            "    computing will bring AI closer to users. As ML democratizes through \n",
            "    accessible tools, its potential to solve global challenges, from climate \n",
            "    change to education, will shape a smarter, sustainable world.\n",
            "\n",
            "Source 2: The future of machine learning (ML) is poised for transformative growth, \n",
            "    driving innovation across industries. Advances in neural networks, quantum \n",
            "    computing, and explainable AI will make ML more powerful and transparent. \n",
            "    It will revolutionize healthcare with precise diagnostics, enhance automation \n",
            "    in manufacturing, and optimize personalized experiences in retail and \n",
            "    entertainment. Ethical AI and robust frameworks will address challenges like\n",
            "    bias and privacy. Seamless integration with IoT, robotics, and edge \n",
            "    computing will bring AI closer to users. As ML democratizes through \n",
            "    accessible tools, its potential to solve global challenges, from climate \n",
            "    change to education, will shape a smarter, sustainable world.\n",
            "\n",
            "Source 3: The future of machine learning (ML) is poised for transformative growth, \n",
            "    driving innovation across industries. Advances in neural networks, quantum \n",
            "    computing, and explainable AI will make ML more powerful and transparent. \n",
            "    It will revolutionize healthcare with precise diagnostics, enhance automation \n",
            "    in manufacturing, and optimize personalized experiences in retail and \n",
            "    entertainment. Ethical AI and robust frameworks will address challenges like\n",
            "    bias and privacy. Seamless integration with IoT, robotics, and edge \n",
            "    computing will bring AI closer to users. As ML democratizes through \n",
            "    accessible tools, its potential to solve global challenges, from climate \n",
            "    change to education, will shape a smarter, sustainable world.\n",
            "\n",
            " *********************** \n",
            "\n",
            "How can I help you? What are traditional dishes in Pakistan?\n",
            "\n",
            "Question: What are traditional dishes in Pakistan?\n",
            "\n",
            "Answer: Biryani, paye, and nihari\n",
            "\n",
            "Sources used:\n",
            "\n",
            "Source 1: hospitality. Whether in bustling cities or quiet villages, the love for \n",
            "    biryani, paye, and nihari reflects the soul of Pakistani cuisine.\n",
            "\n",
            "Source 2: hospitality. Whether in bustling cities or quiet villages, the love for \n",
            "    biryani, paye, and nihari reflects the soul of Pakistani cuisine.\n",
            "\n",
            "Source 3: hospitality. Whether in bustling cities or quiet villages, the love for \n",
            "    biryani, paye, and nihari reflects the soul of Pakistani cuisine.\n",
            "\n",
            " *********************** \n",
            "\n",
            "How can I help you? exit\n"
          ]
        }
      ]
    }
  ]
}